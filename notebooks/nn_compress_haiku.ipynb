{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Compression - Haiku\n",
        "\n",
        "Implementation of several neural network compression techniques (knowledge distillation, pruning, quantization, factorization), in [Haiku](https://github.com/deepmind/dm-haiku).\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Brandhsu/nn-compress-haiku/blob/master/notebooks/nn-compress-haiku.ipynb)\n",
        "\n",
        "The original source code, including this notebook, can be found  [here](https://github.com/Brandhsu/nn-compress-haiku)."
      ],
      "metadata": {
        "id": "m3K9_4DOyJHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "_QoGTCTcd62f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Brandhsu/nn-compress-haiku/\n",
        "%cd nn-compress-haiku\n",
        "!git lfs pull\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "EyuSA08KPKR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe058190-12ee-4afb-9368-78857563bb2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nn-compress-haiku'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 80 (delta 34), reused 62 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), 518.70 KiB | 2.03 MiB/s, done.\n",
            "/content/nn-compress-haiku\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.3.25)\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.9-py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (2.9.2)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (4.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax->-r requirements.txt (line 1)) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from jax->-r requirements.txt (line 1)) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax->-r requirements.txt (line 1)) (3.3.0)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from dm-haiku->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from dm-haiku->-r requirements.txt (line 2)) (0.8.10)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax->-r requirements.txt (line 3)) (0.3.25+cuda11.cudnn805)\n",
            "Collecting chex>=0.1.5\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.9.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (15.0.6.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.9.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->-r requirements.txt (line 4)) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (1.12.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (0.3.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (0.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (5.10.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (2.25.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (0.10.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 7)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 4)) (0.38.4)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets->-r requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets->-r requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets->-r requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (2.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r requirements.txt (line 5)) (1.58.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (5.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->-r requirements.txt (line 4)) (3.2.2)\n",
            "Installing collected packages: jmp, dm-haiku, chex, optax\n",
            "Successfully installed chex-0.1.5 dm-haiku-0.0.9 jmp-0.0.2 optax-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "QQTZf4bVj0fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be training this network on the CIFAR-10 image classification dataset."
      ],
      "metadata": {
        "id": "MtYP2wuRvsmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n 18,50p scripts/02_train_kd.py"
      ],
      "metadata": {
        "id": "_tSRXYZtu00R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82a4422a-6e29-4dfd-9603-bafffa080211"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def teacher_net_fn(batch: Batch) -> jnp.ndarray:\n",
            "    \"\"\"A simple convolutional feedforward deep neural network.\n",
            "\n",
            "    Args:\n",
            "        batch (Batch): A tuple containing (data, labels).\n",
            "\n",
            "    Returns:\n",
            "        jnp.ndarray: output of network\n",
            "    \"\"\"\n",
            "    x = normalize(batch[0])\n",
            "\n",
            "    net = hk.Sequential(\n",
            "        [\n",
            "            hk.Conv2D(output_channels=6 * 3, kernel_shape=(5, 5)),\n",
            "            jax.nn.relu,\n",
            "            hk.AvgPool(window_shape=(2, 2), strides=(2, 2), padding=\"VALID\"),\n",
            "            jax.nn.relu,\n",
            "            hk.Conv2D(output_channels=16 * 3, kernel_shape=(5, 5)),\n",
            "            jax.nn.relu,\n",
            "            hk.AvgPool(window_shape=(2, 2), strides=(2, 2), padding=\"VALID\"),\n",
            "            hk.Flatten(),\n",
            "            hk.Linear(3000),\n",
            "            jax.nn.relu,\n",
            "            hk.Linear(2000),\n",
            "            jax.nn.relu,\n",
            "            hk.Linear(2000),\n",
            "            jax.nn.relu,\n",
            "            hk.Linear(1000),\n",
            "            jax.nn.relu,\n",
            "            hk.Linear(10),\n",
            "        ]\n",
            "    )\n",
            "    return net(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/01_train.py --train-batch-size 64 --train-steps 10001 --eval-steps 1000 --save-dir models"
      ],
      "metadata": {
        "id": "UxK2J4hioivX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4af25a8-a878-4a68-fff0-97e453ac6441"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:11:07.187010: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "[Step 0] Validation / Test accuracy: 0.101 / 0.103.\n",
            "[Step 1000] Validation / Test accuracy: 0.423 / 0.424.\n",
            "[Step 2000] Validation / Test accuracy: 0.602 / 0.598.\n",
            "[Step 3000] Validation / Test accuracy: 0.653 / 0.650.\n",
            "[Step 4000] Validation / Test accuracy: 0.651 / 0.655.\n",
            "[Step 5000] Validation / Test accuracy: 0.652 / 0.649.\n",
            "[Step 6000] Validation / Test accuracy: 0.649 / 0.648.\n",
            "[Step 7000] Validation / Test accuracy: 0.650 / 0.646.\n",
            "[Step 8000] Validation / Test accuracy: 0.650 / 0.647.\n",
            "[Step 9000] Validation / Test accuracy: 0.646 / 0.646.\n",
            "[Step 10000] Validation / Test accuracy: 0.643 / 0.646.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "QYIJ9d9Ad_uB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be applying several techniques to compress the network we just trained."
      ],
      "metadata": {
        "id": "jh5YtJq_v7gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weight Pruning\n",
        "!python scripts/03_compress.py --model-path models/params.pkl --compression-func prune --save-dir figs"
      ],
      "metadata": {
        "id": "HIIGUmJWdJQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544abba7-b77f-4269-f710-5546eb4bfd9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:13:48.895255: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Evaluating the model at 0.00% compression\n",
            "Compression Fraction / Accuracy: 0.00 / 0.624.\n",
            "Compression Fraction / Latency: 0.00 / 0.6368.\n",
            "Evaluating the model at 10.00% compression\n",
            "Compression Fraction / Accuracy: 0.10 / 0.624.\n",
            "Compression Fraction / Latency: 0.10 / 0.4308.\n",
            "Evaluating the model at 20.00% compression\n",
            "Compression Fraction / Accuracy: 0.20 / 0.624.\n",
            "Compression Fraction / Latency: 0.20 / 0.4365.\n",
            "Evaluating the model at 30.00% compression\n",
            "Compression Fraction / Accuracy: 0.30 / 0.624.\n",
            "Compression Fraction / Latency: 0.30 / 0.4641.\n",
            "Evaluating the model at 40.00% compression\n",
            "Compression Fraction / Accuracy: 0.40 / 0.624.\n",
            "Compression Fraction / Latency: 0.40 / 0.4291.\n",
            "Evaluating the model at 50.00% compression\n",
            "Compression Fraction / Accuracy: 0.50 / 0.624.\n",
            "Compression Fraction / Latency: 0.50 / 0.4298.\n",
            "Evaluating the model at 60.00% compression\n",
            "Compression Fraction / Accuracy: 0.60 / 0.624.\n",
            "Compression Fraction / Latency: 0.60 / 0.4327.\n",
            "Evaluating the model at 70.00% compression\n",
            "Compression Fraction / Accuracy: 0.70 / 0.623.\n",
            "Compression Fraction / Latency: 0.70 / 0.4384.\n",
            "Evaluating the model at 80.00% compression\n",
            "Compression Fraction / Accuracy: 0.80 / 0.625.\n",
            "Compression Fraction / Latency: 0.80 / 0.4325.\n",
            "Evaluating the model at 90.00% compression\n",
            "Compression Fraction / Accuracy: 0.90 / 0.622.\n",
            "Compression Fraction / Latency: 0.90 / 0.4304.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Quantization\n",
        "!python scripts/03_compress.py --model-path models/params.pkl --compression-func quant --save-dir figs"
      ],
      "metadata": {
        "id": "EYj-PHXWdnUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0563ea90-69d2-41b6-ff19-dc0894715c04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:18:13.997180: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Evaluating the model at 0.00% compression\n",
            "Compression Fraction / Accuracy: 0.00 / 0.624.\n",
            "Compression Fraction / Latency: 0.00 / 0.6407.\n",
            "Evaluating the model at 10.00% compression\n",
            "Compression Fraction / Accuracy: 0.10 / 0.623.\n",
            "Compression Fraction / Latency: 0.10 / 0.4548.\n",
            "Evaluating the model at 20.00% compression\n",
            "Compression Fraction / Accuracy: 0.20 / 0.624.\n",
            "Compression Fraction / Latency: 0.20 / 0.4477.\n",
            "Evaluating the model at 30.00% compression\n",
            "Compression Fraction / Accuracy: 0.30 / 0.623.\n",
            "Compression Fraction / Latency: 0.30 / 0.4373.\n",
            "Evaluating the model at 40.00% compression\n",
            "Compression Fraction / Accuracy: 0.40 / 0.623.\n",
            "Compression Fraction / Latency: 0.40 / 0.4322.\n",
            "Evaluating the model at 50.00% compression\n",
            "Compression Fraction / Accuracy: 0.50 / 0.624.\n",
            "Compression Fraction / Latency: 0.50 / 0.4333.\n",
            "Evaluating the model at 60.00% compression\n",
            "Compression Fraction / Accuracy: 0.60 / 0.624.\n",
            "Compression Fraction / Latency: 0.60 / 0.4383.\n",
            "Evaluating the model at 70.00% compression\n",
            "Compression Fraction / Accuracy: 0.70 / 0.624.\n",
            "Compression Fraction / Latency: 0.70 / 0.4373.\n",
            "Evaluating the model at 80.00% compression\n",
            "Compression Fraction / Accuracy: 0.80 / 0.624.\n",
            "Compression Fraction / Latency: 0.80 / 0.4682.\n",
            "Evaluating the model at 90.00% compression\n",
            "Compression Fraction / Accuracy: 0.90 / 0.623.\n",
            "Compression Fraction / Latency: 0.90 / 0.4333.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Singular Value Decomposition\n",
        "!python scripts/03_compress.py --model-path models/params.pkl --compression-func svd --save-dir figs"
      ],
      "metadata": {
        "id": "y565xPjBeDKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c16e85-5887-41ec-94cb-c2917ae8da02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:31:44.680737: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Evaluating the model at 0.00% compression\n",
            "Compression Fraction / Accuracy: 0.00 / 0.624.\n",
            "Compression Fraction / Latency: 0.00 / 0.6399.\n",
            "Evaluating the model at 10.00% compression\n",
            "Compression Fraction / Accuracy: 0.10 / 0.624.\n",
            "Compression Fraction / Latency: 0.10 / 0.4356.\n",
            "Evaluating the model at 20.00% compression\n",
            "Compression Fraction / Accuracy: 0.20 / 0.624.\n",
            "Compression Fraction / Latency: 0.20 / 0.4308.\n",
            "Evaluating the model at 30.00% compression\n",
            "Compression Fraction / Accuracy: 0.30 / 0.609.\n",
            "Compression Fraction / Latency: 0.30 / 0.4684.\n",
            "Evaluating the model at 40.00% compression\n",
            "Compression Fraction / Accuracy: 0.40 / 0.505.\n",
            "Compression Fraction / Latency: 0.40 / 0.4381.\n",
            "Evaluating the model at 50.00% compression\n",
            "Compression Fraction / Accuracy: 0.50 / 0.418.\n",
            "Compression Fraction / Latency: 0.50 / 0.4423.\n",
            "Evaluating the model at 60.00% compression\n",
            "Compression Fraction / Accuracy: 0.60 / 0.342.\n",
            "Compression Fraction / Latency: 0.60 / 0.4407.\n",
            "Evaluating the model at 70.00% compression\n",
            "Compression Fraction / Accuracy: 0.70 / 0.292.\n",
            "Compression Fraction / Latency: 0.70 / 0.4394.\n",
            "Evaluating the model at 80.00% compression\n",
            "Compression Fraction / Accuracy: 0.80 / 0.204.\n",
            "Compression Fraction / Latency: 0.80 / 0.4760.\n",
            "Evaluating the model at 90.00% compression\n",
            "Compression Fraction / Accuracy: 0.90 / 0.167.\n",
            "Compression Fraction / Latency: 0.90 / 0.4378.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n",
            "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation"
      ],
      "metadata": {
        "id": "wbc2oJf1oby5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be distilling the knowledge from the network trained in the beginning into this one."
      ],
      "metadata": {
        "id": "vk98yiPPuo7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n 53,77p scripts/02_train_kd.py"
      ],
      "metadata": {
        "id": "w7AvPpzctx3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9395a7-e9f4-4cdb-8226-238220d6fcda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def student_net_fn(batch: Batch) -> jnp.ndarray:\n",
            "    \"\"\"A simple convolutional feedforward deep neural network.\n",
            "\n",
            "    Args:\n",
            "        batch (Batch): A tuple containing (data, labels).\n",
            "\n",
            "    Returns:\n",
            "        jnp.ndarray: output of network\n",
            "    \"\"\"\n",
            "    x = normalize(batch[0])\n",
            "\n",
            "    net = hk.Sequential(\n",
            "        [\n",
            "            hk.Conv2D(output_channels=6 * 3, kernel_shape=(5, 5)),\n",
            "            jax.nn.relu,\n",
            "            hk.AvgPool(window_shape=(2, 2), strides=(2, 2), padding=\"VALID\"),\n",
            "            jax.nn.relu,\n",
            "            hk.Conv2D(output_channels=16 * 3, kernel_shape=(5, 5)),\n",
            "            jax.nn.relu,\n",
            "            hk.AvgPool(window_shape=(2, 2), strides=(2, 2), padding=\"VALID\"),\n",
            "            hk.Flatten(),\n",
            "            hk.Linear(10),\n",
            "        ]\n",
            "    )\n",
            "    return net(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the the teacher's outputs only\n",
        "!python scripts/02_train_kd.py --model-path models/params.pkl --train-batch-size 64 --train-steps 10001 --eval-steps 1000 --alpha 0.0 --save-dir models"
      ],
      "metadata": {
        "id": "ByvjrcLdj2iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff22079c-027a-4d68-da82-68f5c9a208d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:40:05.271035: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "[Step 0] Validation / Test accuracy: 0.080 / 0.077.\n",
            "[Step 1000] Validation / Test accuracy: 0.489 / 0.489.\n",
            "[Step 2000] Validation / Test accuracy: 0.610 / 0.612.\n",
            "[Step 3000] Validation / Test accuracy: 0.652 / 0.653.\n",
            "[Step 4000] Validation / Test accuracy: 0.673 / 0.664.\n",
            "[Step 5000] Validation / Test accuracy: 0.676 / 0.667.\n",
            "[Step 6000] Validation / Test accuracy: 0.675 / 0.667.\n",
            "[Step 7000] Validation / Test accuracy: 0.674 / 0.667.\n",
            "[Step 8000] Validation / Test accuracy: 0.668 / 0.664.\n",
            "[Step 9000] Validation / Test accuracy: 0.664 / 0.658.\n",
            "[Step 10000] Validation / Test accuracy: 0.659 / 0.653.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the ground-truth only\n",
        "!python scripts/02_train_kd.py --model-path models/params.pkl --train-batch-size 64 --train-steps 10001 --eval-steps 1000 --alpha 1.0 --save-dir models"
      ],
      "metadata": {
        "id": "XnS9wrCvnIPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45516fc-0d3d-4fdb-c128-343f225dca9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:25:52.427611: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "[Step 0] Validation / Test accuracy: 0.080 / 0.077.\n",
            "[Step 1000] Validation / Test accuracy: 0.492 / 0.490.\n",
            "[Step 2000] Validation / Test accuracy: 0.612 / 0.615.\n",
            "[Step 3000] Validation / Test accuracy: 0.654 / 0.654.\n",
            "[Step 4000] Validation / Test accuracy: 0.673 / 0.666.\n",
            "[Step 5000] Validation / Test accuracy: 0.679 / 0.669.\n",
            "[Step 6000] Validation / Test accuracy: 0.677 / 0.671.\n",
            "[Step 7000] Validation / Test accuracy: 0.677 / 0.671.\n",
            "[Step 8000] Validation / Test accuracy: 0.671 / 0.669.\n",
            "[Step 9000] Validation / Test accuracy: 0.665 / 0.665.\n",
            "[Step 10000] Validation / Test accuracy: 0.661 / 0.659.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on the teacher's outputs and ground-truth with equal weights\n",
        "!python scripts/02_train_kd.py --model-path models/params.pkl --train-batch-size 64 --train-steps 10001 --eval-steps 1000 --alpha 0.5 --save-dir models"
      ],
      "metadata": {
        "id": "YnHL073fpiMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e6f2db-2f8a-4454-f51d-1cd5af68936b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-20 02:28:48.317223: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "[Step 0] Validation / Test accuracy: 0.080 / 0.077.\n",
            "[Step 1000] Validation / Test accuracy: 0.491 / 0.489.\n",
            "[Step 2000] Validation / Test accuracy: 0.610 / 0.613.\n",
            "[Step 3000] Validation / Test accuracy: 0.657 / 0.651.\n",
            "[Step 4000] Validation / Test accuracy: 0.674 / 0.665.\n",
            "[Step 5000] Validation / Test accuracy: 0.678 / 0.668.\n",
            "[Step 6000] Validation / Test accuracy: 0.677 / 0.671.\n",
            "[Step 7000] Validation / Test accuracy: 0.673 / 0.671.\n",
            "[Step 8000] Validation / Test accuracy: 0.668 / 0.667.\n",
            "[Step 9000] Validation / Test accuracy: 0.664 / 0.662.\n",
            "[Step 10000] Validation / Test accuracy: 0.659 / 0.657.\n"
          ]
        }
      ]
    }
  ]
}